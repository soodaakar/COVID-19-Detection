{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a5fc1a",
   "metadata": {},
   "source": [
    "### Starting Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5aa0b864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘covid_trainer_retraining’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir covid_trainer_retraining\n",
    "!touch covid_trainer_retraining.__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25e7f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_trainer_retraining/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_trainer_retraining/__init__.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "441e8647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_trainer_retraining/train.py\n",
    "import os\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "import IPython.display as display\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import datetime\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9bb71812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "IMG_HEIGHT = 600\n",
    "IMG_WIDTH = 600\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "# 10 is a magic number tuned for local training of this dataset.\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "VALIDATION_IMAGES = 370\n",
    "VALIDATION_STEPS = VALIDATION_IMAGES // BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92b5ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "def decode_img(img, reshape_dims):\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # Resize the image to the desired size.\n",
    "    return tf.image.resize(img, reshape_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "400e761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "CLASS_NAMES = ['Typical_Appearance', 'Negative_for_Pneumonia','Indeterminate_Appearance', 'Atypical_Appearance']\n",
    "\n",
    "def decode_csv(csv_row):\n",
    "    record_defaults = [\"path\", \"target\"]\n",
    "    filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    label = tf.math.equal(CLASS_NAMES, label_string)\n",
    "    return image_bytes, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43da55e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        preprocessing.RandomRotation(factor=0.15),\n",
    "        preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        preprocessing.RandomFlip(),\n",
    "        preprocessing.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n",
    "\n",
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "\n",
    "def read_and_preprocess(image_bytes, label, random_augment=False):\n",
    "    if random_augment:\n",
    "        img = decode_img(image_bytes, [IMG_HEIGHT + 10, IMG_WIDTH + 10])\n",
    "        img = tf.image.random_crop(img, [IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_brightness(img, MAX_DELTA)\n",
    "        img = tf.image.random_contrast(img, CONTRAST_LOWER, CONTRAST_UPPER)\n",
    "        aug_img = img_augmentation(tf.expand_dims(img, axis=0))\n",
    "    else:\n",
    "        img = decode_img(image_bytes, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def read_and_preprocess_with_augment(image_bytes, label):\n",
    "    return read_and_preprocess(image_bytes, label, random_augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19080977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "def load_dataset(csv_of_filenames, batch_size, training=True):\n",
    "    dataset = tf.data.TextLineDataset(filenames=csv_of_filenames) \\\n",
    "        .map(decode_csv).cache()\n",
    "\n",
    "    if training:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess_with_augment) \\\n",
    "            .shuffle(SHUFFLE_BUFFER) \\\n",
    "            .repeat(count=1000) # Indefinately.\n",
    "    else:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess)\n",
    "\n",
    "    # Prefetch prepares the next set of batches while current batch is in use.\n",
    "    return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9bcc7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "train_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/train_data_image_classification_v2.txt\"\n",
    "eval_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/val_data_image_classification_v2.txt\"\n",
    "nclasses = len(CLASS_NAMES)\n",
    "hidden_layer_1_neurons = 400\n",
    "hidden_layer_2_neurons = 100\n",
    "dropout_rate = 0.25\n",
    "num_filters_1 = 64\n",
    "kernel_size_1 = 3\n",
    "pooling_size_1 = 2\n",
    "num_filters_2 = 32\n",
    "kernel_size_2 = 3\n",
    "pooling_size_2 = 2\n",
    "\n",
    "# layers = [\n",
    "#     Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "#            activation='relu',\n",
    "#            input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)),\n",
    "#     MaxPooling2D(pooling_size_1),\n",
    "#     Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "#            activation='relu'),\n",
    "#     MaxPooling2D(pooling_size_2),\n",
    "#     Flatten(),\n",
    "#     Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "#     Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "#     Dropout(dropout_rate),\n",
    "#     Dense(nclasses),\n",
    "#     Softmax()\n",
    "# ]\n",
    "\n",
    "# old_model = Sequential(layers)\n",
    "# old_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy'])\n",
    "\n",
    "train_ds = load_dataset(train_path, BATCH_SIZE)\n",
    "eval_ds = load_dataset(eval_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29b2ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# module_selection = \"mobilenet_v2_100_224\"\n",
    "module_handle = \"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\"\n",
    "\n",
    "NOW = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "checkpoint_path_1 = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/covid_classifier_retraining/{}/model.ckpt\".format(NOW)\n",
    "checkpoint_dir_1 = os.path.dirname(checkpoint_path_1)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint_callback_1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "   checkpoint_path_1, verbose=1, save_weights_only=True,\n",
    "   # Save weights, save_best_only=every epoch.\n",
    "   save_freq='epoch')\n",
    "\n",
    "tensorboard_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/covid_classifier_retraining/{}/tensorboard\".format(NOW)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(tensorboard_path,\n",
    "                                       histogram_freq=1)\n",
    "\n",
    "def build_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", \n",
    "        metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision(thresholds=[0.1,0.15,0.2,0.25,0.3])]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc85f457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_model(num_classes=len(CLASS_NAMES))\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers[-20:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "unfreeze_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b1df150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer_retraining/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer_retraining/train.py\n",
    "\n",
    "hist = model.fit(train_ds, epochs=1000, validation_data=eval_ds,steps_per_epoch=100, verbose=2,validation_steps=VALIDATION_STEPS,\n",
    "                callbacks=[checkpoint_callback_1,tensorboard_cb])\n",
    "\n",
    "model_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/covid_classifier_retraining/{}/model\".format(NOW)\n",
    "\n",
    "tf.saved_model.save(transfer_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9c3a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_trainer_retraining/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_trainer_retraining/config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  # Configure a master worker with 4 T4 GPUs\n",
    "  masterType: n1-highmem-16\n",
    "  masterConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 4\n",
    "      type: NVIDIA_TESLA_K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "048023c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: covid_classifier_retrain210625_030930\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [covid_classifier_retrain210625_030930] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe covid_classifier_retrain210625_030930\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs covid_classifier_retrain210625_030930\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")\n",
    "# PROJECT_ID=qwiklabs-gcp-00-888aa3d75214\n",
    "REGION=\"us-central1\"\n",
    "TFVERSION=\"2.3\"\n",
    "JOBID=covid_classifier_retrain$(date -u +%y%m%d_%H%M%S)\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOBID \\\n",
    "    --module-name=covid_trainer_retraining.train \\\n",
    "    --package-path=covid_trainer_retraining \\\n",
    "    --staging-bucket=gs://qwiklabs-gcp-03-365bf9c0599c-kaggle \\\n",
    "    --python-version=3.7 \\\n",
    "    --runtime-version=${TFVERSION} \\\n",
    "    --region=${REGION} \\\n",
    "    --config covid_trainer_retraining/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f3234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m73"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
