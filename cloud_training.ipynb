{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055b3700",
   "metadata": {},
   "source": [
    "##### Run only if running this notebook for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2f2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bc4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info = pd.read_csv('image_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6678c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for i,j in enumerate(image_info.path):\n",
    "    try:\n",
    "        load = tf.io.read_file(j)\n",
    "    except Exception as e:\n",
    "        ls.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc4de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_available = image_info.drop(index=ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81fefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_available.to_csv('image_classification_v2.txt',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706c8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_non_train = train_test_split(image_available, test_size=0.2, random_state=42,stratify=image_available.target)\n",
    "X_val, X_test = train_test_split(X_non_train, test_size=0.5, random_state=42,stratify=X_non_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6142031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train:  (4744, 2)\n",
      "Shape of train:  (593, 2)\n",
      "Shape of train:  (593, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train: \", X_train.shape)\n",
    "print(\"Shape of train: \", X_val.shape)\n",
    "print(\"Shape of train: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd99628",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(r'train_data_image_classification.txt',index=False,header=False)\n",
    "X_val.to_csv(r'val_data_image_classification.txt',index=False,header=False)\n",
    "X_test.to_csv(r'test_data_image_classification.txt',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf91ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://train_data_image_classification.txt [Content-Type=text/plain]...\n",
      "/ [1 files][394.8 KiB/394.8 KiB]                                                \n",
      "Operation completed over 1 objects/394.8 KiB.                                    \n",
      "Copying file://val_data_image_classification.txt [Content-Type=text/plain]...\n",
      "/ [1 files][ 49.4 KiB/ 49.4 KiB]                                                \n",
      "Operation completed over 1 objects/49.4 KiB.                                     \n",
      "Copying file://test_data_image_classification.txt [Content-Type=text/plain]...\n",
      "/ [1 files][ 49.4 KiB/ 49.4 KiB]                                                \n",
      "Operation completed over 1 objects/49.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp train_data_image_classification.txt gs://qwiklabs-gcp-03-365bf9c0599c-kaggle\n",
    "!gsutil cp val_data_image_classification.txt gs://qwiklabs-gcp-03-365bf9c0599c-kaggle\n",
    "!gsutil cp test_data_image_classification.txt gs://qwiklabs-gcp-03-365bf9c0599c-kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc8a40",
   "metadata": {},
   "source": [
    "### Starting Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7f82fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘covid_trainer’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir covid_trainer\n",
    "!touch covid_trainer.__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7ba59c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_trainer/train.py\n",
    "import os\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "import IPython.display as display\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import datetime\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0b92714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "IMG_HEIGHT = 600\n",
    "IMG_WIDTH = 600\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "# 10 is a magic number tuned for local training of this dataset.\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "VALIDATION_IMAGES = 370\n",
    "VALIDATION_STEPS = VALIDATION_IMAGES // BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "43e94f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "def decode_img(img, reshape_dims):\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # Resize the image to the desired size.\n",
    "    return tf.image.resize(img, reshape_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "d56ed192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = tf.io.read_file(\n",
    "#     \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/train/000a312787f2.jpg\")\n",
    "\n",
    "# # Uncomment to see the image string.\n",
    "# #print(img)\n",
    "# img = decode_img(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "# plt.imshow((img.numpy()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c8e1793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "CLASS_NAMES = ['Typical_Appearance', 'Negative_for_Pneumonia','Indeterminate_Appearance', 'Atypical_Appearance']\n",
    "\n",
    "def decode_csv(csv_row):\n",
    "    record_defaults = [\"path\", \"target\"]\n",
    "    filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    label = tf.math.equal(CLASS_NAMES, label_string)\n",
    "    return image_bytes, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "0d3ddaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        preprocessing.RandomRotation(factor=0.15),\n",
    "        preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        preprocessing.RandomFlip(),\n",
    "        preprocessing.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n",
    "\n",
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "\n",
    "def read_and_preprocess(image_bytes, label, random_augment=False):\n",
    "    if random_augment:\n",
    "        img = decode_img(image_bytes, [IMG_HEIGHT + 10, IMG_WIDTH + 10])\n",
    "        img = tf.image.random_crop(img, [IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_brightness(img, MAX_DELTA)\n",
    "        img = tf.image.random_contrast(img, CONTRAST_LOWER, CONTRAST_UPPER)\n",
    "        aug_img = img_augmentation(tf.expand_dims(img, axis=0))\n",
    "    else:\n",
    "        img = decode_img(image_bytes, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def read_and_preprocess_with_augment(image_bytes, label):\n",
    "    return read_and_preprocess(image_bytes, label, random_augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "43728b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "def load_dataset(csv_of_filenames, batch_size, training=True):\n",
    "    dataset = tf.data.TextLineDataset(filenames=csv_of_filenames) \\\n",
    "        .map(decode_csv).cache()\n",
    "\n",
    "    if training:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess_with_augment) \\\n",
    "            .shuffle(SHUFFLE_BUFFER) \\\n",
    "            .repeat(count=None)  # Indefinately.\n",
    "    else:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess) \\\n",
    "            .repeat()  \n",
    "\n",
    "    # Prefetch prepares the next set of batches while current batch is in use.\n",
    "    return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "812e4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = \"/home/jupyter/train_data_image_classification.txt\"\n",
    "# train_data = load_dataset(train_path, 1)\n",
    "# itr = iter(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0af4a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch, label_batch = next(itr)\n",
    "# img = image_batch[0]\n",
    "# plt.imshow(img)\n",
    "# print(label_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "30eaa0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "train_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/train_data_image_classification_v2.txt\"\n",
    "eval_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/val_data_image_classification_v2.txt\"\n",
    "nclasses = len(CLASS_NAMES)\n",
    "hidden_layer_1_neurons = 400\n",
    "hidden_layer_2_neurons = 100\n",
    "dropout_rate = 0.25\n",
    "num_filters_1 = 64\n",
    "kernel_size_1 = 3\n",
    "pooling_size_1 = 2\n",
    "num_filters_2 = 32\n",
    "kernel_size_2 = 3\n",
    "pooling_size_2 = 2\n",
    "\n",
    "# layers = [\n",
    "#     Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "#            activation='relu',\n",
    "#            input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)),\n",
    "#     MaxPooling2D(pooling_size_1),\n",
    "#     Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "#            activation='relu'),\n",
    "#     MaxPooling2D(pooling_size_2),\n",
    "#     Flatten(),\n",
    "#     Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "#     Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "#     Dropout(dropout_rate),\n",
    "#     Dense(nclasses),\n",
    "#     Softmax()\n",
    "# ]\n",
    "\n",
    "# old_model = Sequential(layers)\n",
    "# old_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy'])\n",
    "\n",
    "train_ds = load_dataset(train_path, BATCH_SIZE)\n",
    "eval_ds = load_dataset(eval_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3a5ccece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_model.fit_generator(\n",
    "#     train_ds,\n",
    "#     epochs=5,\n",
    "#     steps_per_epoch=5,\n",
    "#     validation_data=eval_ds,\n",
    "#     validation_steps=VALIDATION_STEPS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e7f26ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# module_selection = \"mobilenet_v2_100_224\"\n",
    "module_handle = \"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\"\n",
    "\n",
    "NOW = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "checkpoint_path_1 = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/covid_classifier/{}/model.ckpt\".format(NOW)\n",
    "checkpoint_dir_1 = os.path.dirname(checkpoint_path_1)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint_callback_1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "   checkpoint_path_1, verbose=1, save_weights_only=True,\n",
    "   # Save weights, save_best_only=every epoch.\n",
    "   save_freq='epoch')\n",
    "\n",
    "tensorboard_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/covid_classifier/{}/tensorboard\".format(NOW)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(tensorboard_path,\n",
    "                                       histogram_freq=1)\n",
    "\n",
    "with strategy.scope():\n",
    "    transfer_model = tf.keras.Sequential([\n",
    "        hub.KerasLayer(module_handle, trainable=True),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(\n",
    "            nclasses,\n",
    "            activation='softmax',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "    ])\n",
    "    transfer_model.build((None,)+(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    transfer_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision(thresholds=[0.1,0.15,0.2,0.25,0.3]),tf.keras.metrics.Recall(\n",
    "    thresholds=[0.1,0.15,0.2,0.25,0.3])])\n",
    "    \n",
    "transfer_model.summary()\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "ce9c5545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "transfer_model.fit(\n",
    "    train_ds,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=eval_ds,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    callbacks=[checkpoint_callback_1, tensorboard_cb,earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "674c816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to covid_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a covid_trainer/train.py\n",
    "\n",
    "model_path = \"gs://qwiklabs-gcp-03-365bf9c0599c-kaggle/covid_classifier/{}/model\".format(NOW)\n",
    "\n",
    "tf.saved_model.save(transfer_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "21ba2658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_trainer/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_trainer/config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  # Configure a master worker with 4 T4 GPUs\n",
    "  masterType: n1-highmem-16\n",
    "  masterConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 8\n",
    "      type: NVIDIA_TESLA_K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "bfec62e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: covid_classifier_trainable_210625_015417\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [covid_classifier_trainable_210625_015417] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe covid_classifier_trainable_210625_015417\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs covid_classifier_trainable_210625_015417\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")\n",
    "# PROJECT_ID=qwiklabs-gcp-00-888aa3d75214\n",
    "REGION=\"us-central1\"\n",
    "TFVERSION=\"2.3\"\n",
    "JOBID=covid_classifier_trainable_$(date -u +%y%m%d_%H%M%S)\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOBID \\\n",
    "    --module-name=covid_trainer.train \\\n",
    "    --package-path=covid_trainer \\\n",
    "    --staging-bucket=gs://qwiklabs-gcp-03-365bf9c0599c-kaggle \\\n",
    "    --python-version=3.7 \\\n",
    "    --runtime-version=${TFVERSION} \\\n",
    "    --region=${REGION} \\\n",
    "    --config covid_trainer/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7040f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m73"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
